{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8d8c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from emrgpt.model import TimelineBasedEmrGPT\n",
    "from emrgpt.trainer import TimelineDS\n",
    "import torch\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "\n",
    "dotenv.load_dotenv('.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee489122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimelineBasedEmrGPT(\n",
       "  (proj): Linear(in_features=13, out_features=32, bias=True)\n",
       "  (positional_encoding): FixedPositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): AkDecoderBlock(\n",
       "      (self_attention): AkMultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-9): 10 x AkSelfAttentionHead(\n",
       "            (key): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=3, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=30, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=32, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TimelineBasedEmrGPT(\n",
    "    n_event_types=13,\n",
    "    d_model=32,\n",
    "    block_size=24,\n",
    "    max_len=24,\n",
    "    n_head=10,\n",
    "    n_layer=10,\n",
    "    dropout=0.2,\n",
    ").to('cuda')\n",
    "\n",
    "model.load_state_dict(torch.load('cache/savedmodels/TimelineBasedEmrGPT.pt'))\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613f321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<emrgpt.trainer.TimelineDS at 0x7770257435c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TimelineDS()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45d5c4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>spo2</th>\n",
       "      <th>glucose</th>\n",
       "      <th>norepi_eq_rate</th>\n",
       "      <th>vent_hfnc</th>\n",
       "      <th>vent_suppo2</th>\n",
       "      <th>vent_noninvasive</th>\n",
       "      <th>vent_invasive</th>\n",
       "      <th>vent_trach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.015945</td>\n",
       "      <td>120.280678</td>\n",
       "      <td>73.730453</td>\n",
       "      <td>14.756079</td>\n",
       "      <td>37.250565</td>\n",
       "      <td>100.794189</td>\n",
       "      <td>106946.273438</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>-0.036907</td>\n",
       "      <td>-0.116157</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>0.061125</td>\n",
       "      <td>0.048466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.398155</td>\n",
       "      <td>120.181458</td>\n",
       "      <td>78.935555</td>\n",
       "      <td>13.730887</td>\n",
       "      <td>37.080048</td>\n",
       "      <td>101.638298</td>\n",
       "      <td>123824.835938</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>-0.042171</td>\n",
       "      <td>-0.156667</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.059209</td>\n",
       "      <td>0.037101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.027328</td>\n",
       "      <td>122.257576</td>\n",
       "      <td>81.011070</td>\n",
       "      <td>14.630562</td>\n",
       "      <td>36.919250</td>\n",
       "      <td>103.214905</td>\n",
       "      <td>133499.453125</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>-0.051988</td>\n",
       "      <td>-0.165182</td>\n",
       "      <td>0.048639</td>\n",
       "      <td>0.056198</td>\n",
       "      <td>0.032363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.645485</td>\n",
       "      <td>126.165276</td>\n",
       "      <td>83.607140</td>\n",
       "      <td>15.907503</td>\n",
       "      <td>36.759117</td>\n",
       "      <td>104.583427</td>\n",
       "      <td>146454.781250</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>-0.067481</td>\n",
       "      <td>-0.173801</td>\n",
       "      <td>0.055059</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.033732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.387558</td>\n",
       "      <td>129.440048</td>\n",
       "      <td>85.951973</td>\n",
       "      <td>16.811710</td>\n",
       "      <td>36.703255</td>\n",
       "      <td>104.338867</td>\n",
       "      <td>154015.421875</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>-0.083730</td>\n",
       "      <td>-0.192458</td>\n",
       "      <td>0.051596</td>\n",
       "      <td>0.066790</td>\n",
       "      <td>0.035101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>98.106346</td>\n",
       "      <td>129.621262</td>\n",
       "      <td>86.159973</td>\n",
       "      <td>17.194729</td>\n",
       "      <td>36.824699</td>\n",
       "      <td>102.943184</td>\n",
       "      <td>148125.046875</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>-0.087210</td>\n",
       "      <td>-0.215878</td>\n",
       "      <td>0.049650</td>\n",
       "      <td>0.077756</td>\n",
       "      <td>0.033969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95.489601</td>\n",
       "      <td>126.842888</td>\n",
       "      <td>84.980652</td>\n",
       "      <td>17.102505</td>\n",
       "      <td>36.840492</td>\n",
       "      <td>101.641464</td>\n",
       "      <td>132640.843750</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>-0.083406</td>\n",
       "      <td>-0.237758</td>\n",
       "      <td>0.050986</td>\n",
       "      <td>0.085694</td>\n",
       "      <td>0.030702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93.417038</td>\n",
       "      <td>124.768654</td>\n",
       "      <td>82.972481</td>\n",
       "      <td>17.143862</td>\n",
       "      <td>36.612068</td>\n",
       "      <td>101.642517</td>\n",
       "      <td>113584.804688</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>-0.079691</td>\n",
       "      <td>-0.252201</td>\n",
       "      <td>0.055746</td>\n",
       "      <td>0.088552</td>\n",
       "      <td>0.034550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92.795082</td>\n",
       "      <td>125.894005</td>\n",
       "      <td>82.330223</td>\n",
       "      <td>17.347012</td>\n",
       "      <td>36.206512</td>\n",
       "      <td>103.262779</td>\n",
       "      <td>92984.250000</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>-0.081459</td>\n",
       "      <td>-0.264087</td>\n",
       "      <td>0.055312</td>\n",
       "      <td>0.096997</td>\n",
       "      <td>0.050526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93.648445</td>\n",
       "      <td>130.461288</td>\n",
       "      <td>83.265701</td>\n",
       "      <td>17.528633</td>\n",
       "      <td>35.767387</td>\n",
       "      <td>105.302292</td>\n",
       "      <td>67232.515625</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>-0.087984</td>\n",
       "      <td>-0.277362</td>\n",
       "      <td>0.045690</td>\n",
       "      <td>0.120759</td>\n",
       "      <td>0.071928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>95.192078</td>\n",
       "      <td>133.999893</td>\n",
       "      <td>85.913017</td>\n",
       "      <td>16.864897</td>\n",
       "      <td>35.399078</td>\n",
       "      <td>105.897102</td>\n",
       "      <td>51341.957031</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>-0.096418</td>\n",
       "      <td>-0.289197</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.150444</td>\n",
       "      <td>0.086749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>96.145882</td>\n",
       "      <td>134.156876</td>\n",
       "      <td>88.726471</td>\n",
       "      <td>15.433634</td>\n",
       "      <td>35.283760</td>\n",
       "      <td>104.663361</td>\n",
       "      <td>52610.007812</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>-0.100064</td>\n",
       "      <td>-0.292830</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>0.172366</td>\n",
       "      <td>0.084099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    heart_rate         sbp        dbp  resp_rate  temperature        spo2  \\\n",
       "0    65.000000  121.000000  82.000000  12.000000    38.000000   99.000000   \n",
       "1    98.015945  120.280678  73.730453  14.756079    37.250565  100.794189   \n",
       "2    98.398155  120.181458  78.935555  13.730887    37.080048  101.638298   \n",
       "3   100.027328  122.257576  81.011070  14.630562    36.919250  103.214905   \n",
       "4   100.645485  126.165276  83.607140  15.907503    36.759117  104.583427   \n",
       "5   100.387558  129.440048  85.951973  16.811710    36.703255  104.338867   \n",
       "6    98.106346  129.621262  86.159973  17.194729    36.824699  102.943184   \n",
       "7    95.489601  126.842888  84.980652  17.102505    36.840492  101.641464   \n",
       "8    93.417038  124.768654  82.972481  17.143862    36.612068  101.642517   \n",
       "9    92.795082  125.894005  82.330223  17.347012    36.206512  103.262779   \n",
       "10   93.648445  130.461288  83.265701  17.528633    35.767387  105.302292   \n",
       "11   95.192078  133.999893  85.913017  16.864897    35.399078  105.897102   \n",
       "12   96.145882  134.156876  88.726471  15.433634    35.283760  104.663361   \n",
       "\n",
       "          glucose  norepi_eq_rate  vent_hfnc  vent_suppo2  vent_noninvasive  \\\n",
       "0      120.000000        0.000000   0.000000     0.000000          0.000000   \n",
       "1   106946.273438        0.001833  -0.036907    -0.116157          0.023932   \n",
       "2   123824.835938        0.003296  -0.042171    -0.156667          0.033381   \n",
       "3   133499.453125        0.003761  -0.051988    -0.165182          0.048639   \n",
       "4   146454.781250        0.003333  -0.067481    -0.173801          0.055059   \n",
       "5   154015.421875        0.002949  -0.083730    -0.192458          0.051596   \n",
       "6   148125.046875        0.003467  -0.087210    -0.215878          0.049650   \n",
       "7   132640.843750        0.004692  -0.083406    -0.237758          0.050986   \n",
       "8   113584.804688        0.005667  -0.079691    -0.252201          0.055746   \n",
       "9    92984.250000        0.005674  -0.081459    -0.264087          0.055312   \n",
       "10   67232.515625        0.004525  -0.087984    -0.277362          0.045690   \n",
       "11   51341.957031        0.003003  -0.096418    -0.289197          0.027681   \n",
       "12   52610.007812        0.002202  -0.100064    -0.292830          0.012356   \n",
       "\n",
       "    vent_invasive  vent_trach  \n",
       "0        0.000000    0.000000  \n",
       "1        0.061125    0.048466  \n",
       "2        0.059209    0.037101  \n",
       "3        0.056198    0.032363  \n",
       "4        0.058111    0.033732  \n",
       "5        0.066790    0.035101  \n",
       "6        0.077756    0.033969  \n",
       "7        0.085694    0.030702  \n",
       "8        0.088552    0.034550  \n",
       "9        0.096997    0.050526  \n",
       "10       0.120759    0.071928  \n",
       "11       0.150444    0.086749  \n",
       "12       0.172366    0.084099  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = model.generate(\n",
    "    seed=ds.normalize(\n",
    "        torch.tensor([65., 121., 82., 12., 38., 99., 120., 0., 0., 0., 0., 0., 0.], device='cuda').unsqueeze(0)\n",
    "    ).unsqueeze(0)\n",
    ")\n",
    "g_denorm = ds.denormalize(g)\n",
    "df = pd.DataFrame(data=g_denorm.detach().cpu(), columns=ds.features)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6f3be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>spo2</th>\n",
       "      <th>glucose</th>\n",
       "      <th>norepi_eq_rate</th>\n",
       "      <th>vent_hfnc</th>\n",
       "      <th>vent_suppo2</th>\n",
       "      <th>vent_noninvasive</th>\n",
       "      <th>vent_invasive</th>\n",
       "      <th>vent_trach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.126625</td>\n",
       "      <td>108.805267</td>\n",
       "      <td>67.396133</td>\n",
       "      <td>18.017878</td>\n",
       "      <td>38.230335</td>\n",
       "      <td>93.500847</td>\n",
       "      <td>101155.625000</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>-0.020251</td>\n",
       "      <td>-0.257890</td>\n",
       "      <td>0.042337</td>\n",
       "      <td>0.120837</td>\n",
       "      <td>-0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.082596</td>\n",
       "      <td>110.134888</td>\n",
       "      <td>73.557442</td>\n",
       "      <td>14.871230</td>\n",
       "      <td>36.523766</td>\n",
       "      <td>102.099754</td>\n",
       "      <td>140243.859375</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>-0.042195</td>\n",
       "      <td>-0.296538</td>\n",
       "      <td>0.063482</td>\n",
       "      <td>0.139033</td>\n",
       "      <td>0.016286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.631401</td>\n",
       "      <td>114.932678</td>\n",
       "      <td>77.781364</td>\n",
       "      <td>15.011525</td>\n",
       "      <td>36.646286</td>\n",
       "      <td>104.216454</td>\n",
       "      <td>128890.835938</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>-0.058975</td>\n",
       "      <td>-0.303178</td>\n",
       "      <td>0.069137</td>\n",
       "      <td>0.131352</td>\n",
       "      <td>0.014519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.722847</td>\n",
       "      <td>120.820076</td>\n",
       "      <td>80.300064</td>\n",
       "      <td>16.363865</td>\n",
       "      <td>36.507973</td>\n",
       "      <td>105.660561</td>\n",
       "      <td>138110.250000</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>-0.076348</td>\n",
       "      <td>-0.310995</td>\n",
       "      <td>0.075117</td>\n",
       "      <td>0.133808</td>\n",
       "      <td>0.017847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96.183174</td>\n",
       "      <td>125.680359</td>\n",
       "      <td>82.420845</td>\n",
       "      <td>17.039083</td>\n",
       "      <td>36.561054</td>\n",
       "      <td>105.562920</td>\n",
       "      <td>138208.609375</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>-0.090881</td>\n",
       "      <td>-0.322787</td>\n",
       "      <td>0.071857</td>\n",
       "      <td>0.149437</td>\n",
       "      <td>0.024520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94.726097</td>\n",
       "      <td>126.226494</td>\n",
       "      <td>83.526680</td>\n",
       "      <td>17.132236</td>\n",
       "      <td>36.753139</td>\n",
       "      <td>103.971451</td>\n",
       "      <td>128054.015625</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>-0.096405</td>\n",
       "      <td>-0.339873</td>\n",
       "      <td>0.068149</td>\n",
       "      <td>0.169239</td>\n",
       "      <td>0.025107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>91.723129</td>\n",
       "      <td>124.037872</td>\n",
       "      <td>82.914688</td>\n",
       "      <td>17.013645</td>\n",
       "      <td>36.804108</td>\n",
       "      <td>102.349396</td>\n",
       "      <td>111454.046875</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>-0.091475</td>\n",
       "      <td>-0.353332</td>\n",
       "      <td>0.069410</td>\n",
       "      <td>0.183404</td>\n",
       "      <td>0.019463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89.918213</td>\n",
       "      <td>121.698395</td>\n",
       "      <td>81.488052</td>\n",
       "      <td>17.057571</td>\n",
       "      <td>36.637569</td>\n",
       "      <td>102.405556</td>\n",
       "      <td>88028.937500</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>-0.086969</td>\n",
       "      <td>-0.360173</td>\n",
       "      <td>0.072209</td>\n",
       "      <td>0.191068</td>\n",
       "      <td>0.021647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.040672</td>\n",
       "      <td>122.734245</td>\n",
       "      <td>81.071159</td>\n",
       "      <td>17.411385</td>\n",
       "      <td>36.252075</td>\n",
       "      <td>104.079338</td>\n",
       "      <td>60593.703125</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>-0.087818</td>\n",
       "      <td>-0.369001</td>\n",
       "      <td>0.073519</td>\n",
       "      <td>0.205213</td>\n",
       "      <td>0.038157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>91.007950</td>\n",
       "      <td>126.934708</td>\n",
       "      <td>82.479279</td>\n",
       "      <td>17.611546</td>\n",
       "      <td>35.783527</td>\n",
       "      <td>106.120811</td>\n",
       "      <td>31517.970703</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>-0.094618</td>\n",
       "      <td>-0.382049</td>\n",
       "      <td>0.063251</td>\n",
       "      <td>0.232941</td>\n",
       "      <td>0.061686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>93.050140</td>\n",
       "      <td>130.784073</td>\n",
       "      <td>85.713295</td>\n",
       "      <td>16.795399</td>\n",
       "      <td>35.394711</td>\n",
       "      <td>106.652512</td>\n",
       "      <td>18433.330078</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.102542</td>\n",
       "      <td>-0.393264</td>\n",
       "      <td>0.042906</td>\n",
       "      <td>0.262644</td>\n",
       "      <td>0.079065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93.855026</td>\n",
       "      <td>131.279709</td>\n",
       "      <td>88.417229</td>\n",
       "      <td>15.261024</td>\n",
       "      <td>35.334110</td>\n",
       "      <td>105.274010</td>\n",
       "      <td>21034.099609</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>-0.105752</td>\n",
       "      <td>-0.390468</td>\n",
       "      <td>0.027493</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.078038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    heart_rate         sbp        dbp  resp_rate  temperature        spo2  \\\n",
       "0     1.000000    0.100000   1.000000   0.130000    18.200001    0.010000   \n",
       "1    67.126625  108.805267  67.396133  18.017878    38.230335   93.500847   \n",
       "2    93.082596  110.134888  73.557442  14.871230    36.523766  102.099754   \n",
       "3    94.631401  114.932678  77.781364  15.011525    36.646286  104.216454   \n",
       "4    95.722847  120.820076  80.300064  16.363865    36.507973  105.660561   \n",
       "5    96.183174  125.680359  82.420845  17.039083    36.561054  105.562920   \n",
       "6    94.726097  126.226494  83.526680  17.132236    36.753139  103.971451   \n",
       "7    91.723129  124.037872  82.914688  17.013645    36.804108  102.349396   \n",
       "8    89.918213  121.698395  81.488052  17.057571    36.637569  102.405556   \n",
       "9    90.040672  122.734245  81.071159  17.411385    36.252075  104.079338   \n",
       "10   91.007950  126.934708  82.479279  17.611546    35.783527  106.120811   \n",
       "11   93.050140  130.784073  85.713295  16.795399    35.394711  106.652512   \n",
       "12   93.855026  131.279709  88.417229  15.261024    35.334110  105.274010   \n",
       "\n",
       "          glucose  norepi_eq_rate  vent_hfnc  vent_suppo2  vent_noninvasive  \\\n",
       "0        0.120000        0.000000   0.000000     0.000000          0.000000   \n",
       "1   101155.625000        0.001525  -0.020251    -0.257890          0.042337   \n",
       "2   140243.859375        0.002560  -0.042195    -0.296538          0.063482   \n",
       "3   128890.835938        0.003842  -0.058975    -0.303178          0.069137   \n",
       "4   138110.250000        0.003536  -0.076348    -0.310995          0.075117   \n",
       "5   138208.609375        0.003279  -0.090881    -0.322787          0.071857   \n",
       "6   128054.015625        0.003990  -0.096405    -0.339873          0.068149   \n",
       "7   111454.046875        0.005367  -0.091475    -0.353332          0.069410   \n",
       "8    88028.937500        0.006584  -0.086969    -0.360173          0.072209   \n",
       "9    60593.703125        0.006664  -0.087818    -0.369001          0.073519   \n",
       "10   31517.970703        0.005488  -0.094618    -0.382049          0.063251   \n",
       "11   18433.330078        0.003911  -0.102542    -0.393264          0.042906   \n",
       "12   21034.099609        0.003062  -0.105752    -0.390468          0.027493   \n",
       "\n",
       "    vent_invasive  vent_trach  \n",
       "0        0.000000    0.000000  \n",
       "1        0.120837   -0.000843  \n",
       "2        0.139033    0.016286  \n",
       "3        0.131352    0.014519  \n",
       "4        0.133808    0.017847  \n",
       "5        0.149437    0.024520  \n",
       "6        0.169239    0.025107  \n",
       "7        0.183404    0.019463  \n",
       "8        0.191068    0.021647  \n",
       "9        0.205213    0.038157  \n",
       "10       0.232941    0.061686  \n",
       "11       0.262644    0.079065  \n",
       "12       0.283582    0.078038  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca65f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
